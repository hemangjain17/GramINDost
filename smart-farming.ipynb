{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9569080,"sourceType":"datasetVersion","datasetId":5832470}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd \nimport numpy as np \nfrom transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom datasets import Dataset\nimport warnings \nimport pandas as pd\nimport torch\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-29T21:43:30.497353Z","iopub.execute_input":"2024-10-29T21:43:30.498041Z","iopub.status.idle":"2024-10-29T21:43:48.891667Z","shell.execute_reply.started":"2024-10-29T21:43:30.497996Z","shell.execute_reply":"2024-10-29T21:43:48.890770Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"data=pd.read_csv('/kaggle/input/crop-dataset/Crop_recommendation.csv')\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-29T21:43:48.893503Z","iopub.execute_input":"2024-10-29T21:43:48.894575Z","iopub.status.idle":"2024-10-29T21:43:48.929073Z","shell.execute_reply.started":"2024-10-29T21:43:48.894529Z","shell.execute_reply":"2024-10-29T21:43:48.928143Z"},"trusted":true},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"    N   P   K  temperature   humidity        ph    rainfall label\n0  90  42  43    20.879744  82.002744  6.502985  202.935536  rice\n1  85  58  41    21.770462  80.319644  7.038096  226.655537  rice\n2  60  55  44    23.004459  82.320763  7.840207  263.964248  rice\n3  74  35  40    26.491096  80.158363  6.980401  242.864034  rice\n4  78  42  42    20.130175  81.604873  7.628473  262.717340  rice","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>N</th>\n      <th>P</th>\n      <th>K</th>\n      <th>temperature</th>\n      <th>humidity</th>\n      <th>ph</th>\n      <th>rainfall</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>90</td>\n      <td>42</td>\n      <td>43</td>\n      <td>20.879744</td>\n      <td>82.002744</td>\n      <td>6.502985</td>\n      <td>202.935536</td>\n      <td>rice</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>85</td>\n      <td>58</td>\n      <td>41</td>\n      <td>21.770462</td>\n      <td>80.319644</td>\n      <td>7.038096</td>\n      <td>226.655537</td>\n      <td>rice</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>60</td>\n      <td>55</td>\n      <td>44</td>\n      <td>23.004459</td>\n      <td>82.320763</td>\n      <td>7.840207</td>\n      <td>263.964248</td>\n      <td>rice</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>74</td>\n      <td>35</td>\n      <td>40</td>\n      <td>26.491096</td>\n      <td>80.158363</td>\n      <td>6.980401</td>\n      <td>242.864034</td>\n      <td>rice</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>78</td>\n      <td>42</td>\n      <td>42</td>\n      <td>20.130175</td>\n      <td>81.604873</td>\n      <td>7.628473</td>\n      <td>262.717340</td>\n      <td>rice</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\nfrom transformers import DataCollatorWithPadding\nfrom datasets import Dataset\nfrom sklearn.preprocessing import LabelEncoder\nimport torch\n\ndf = pd.read_csv('/kaggle/input/crop-dataset/Crop_recommendation.csv') \n\ndef row_to_text(row):\n    return (f\"The nitrogen content is {row['N']}, phosphorus is {row['P']}, \"\n            f\"and potassium is {row['K']}, with a temperature of {row['temperature']}Â°C, \"\n            f\"humidity of {row['humidity']}%, pH of {row['ph']}, \"\n            f\"and rainfall of {row['rainfall']}mm.\")","metadata":{"execution":{"iopub.status.busy":"2024-10-29T21:43:48.930283Z","iopub.execute_input":"2024-10-29T21:43:48.930936Z","iopub.status.idle":"2024-10-29T21:43:48.943104Z","shell.execute_reply.started":"2024-10-29T21:43:48.930890Z","shell.execute_reply":"2024-10-29T21:43:48.942015Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"df['text'] = df.apply(row_to_text, axis=1)\n\nlabel_encoder = LabelEncoder()\ndf['label'] = label_encoder.fit_transform(df['label'])\n\ntrain_texts, valid_texts, train_labels, valid_labels = train_test_split(df['text'], df['label'], test_size=0.2)\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\ndef tokenize_function(texts):\n    return tokenizer(texts, truncation=True, padding=True)\n\ntrain_encodings = tokenize_function(train_texts.tolist())\nvalid_encodings = tokenize_function(valid_texts.tolist())\n\ntrain_dataset = Dataset.from_dict({\n    'input_ids': train_encodings['input_ids'],\n    'attention_mask': train_encodings['attention_mask'],\n    'labels': train_labels\n})\n\nvalid_dataset = Dataset.from_dict({\n    'input_ids': valid_encodings['input_ids'],\n    'attention_mask': valid_encodings['attention_mask'],\n    'labels': valid_labels\n})","metadata":{"execution":{"iopub.status.busy":"2024-10-29T21:43:48.944870Z","iopub.execute_input":"2024-10-29T21:43:48.945180Z","iopub.status.idle":"2024-10-29T21:43:53.840674Z","shell.execute_reply.started":"2024-10-29T21:43:48.945147Z","shell.execute_reply":"2024-10-29T21:43:53.839901Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a60ef8032b304977b86bbccd774aaa34"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"881ae95b28274028b6c5fdff4d76809a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28551e7044984214b5388b1aee9fd799"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df27e353997944b48a7d1a58882364f7"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(df['label'].unique()))","metadata":{"execution":{"iopub.status.busy":"2024-10-29T21:43:53.841867Z","iopub.execute_input":"2024-10-29T21:43:53.842608Z","iopub.status.idle":"2024-10-29T21:43:56.358321Z","shell.execute_reply.started":"2024-10-29T21:43:53.842562Z","shell.execute_reply":"2024-10-29T21:43:56.357508Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63431f5602734192abbdc459e8aa8481"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score\n\ndef compute_metrics(pred):\n    labels = pred.label_ids\n    preds = pred.predictions.argmax(-1)\n    acc = accuracy_score(labels, preds)\n    f1 = f1_score(labels, preds, average='weighted')\n    \n    return {'accuracy':acc,\n            'f1' :f1   \n    }","metadata":{"execution":{"iopub.status.busy":"2024-10-22T21:14:44.803545Z","iopub.execute_input":"2024-10-22T21:14:44.803846Z","iopub.status.idle":"2024-10-22T21:14:44.809246Z","shell.execute_reply.started":"2024-10-22T21:14:44.803813Z","shell.execute_reply":"2024-10-22T21:14:44.808225Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"from transformers import TrainerCallback\n\nclass CustomCallback(TrainerCallback):\n    def on_epoch_begin(self, args, state, control, **kwargs):\n        print(f\"\\nEpoch {state.epoch + 1}/{state.num_train_epochs} started.\")","metadata":{"execution":{"iopub.status.busy":"2024-10-22T21:14:44.810596Z","iopub.execute_input":"2024-10-22T21:14:44.811282Z","iopub.status.idle":"2024-10-22T21:14:44.818696Z","shell.execute_reply.started":"2024-10-22T21:14:44.811224Z","shell.execute_reply":"2024-10-22T21:14:44.817766Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## Training ","metadata":{}},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir='./results',\n    num_train_epochs=10,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=16,\n    evaluation_strategy=\"steps\",\n    logging_dir='./logs',\n    logging_steps=200,\n    save_steps=200,\n    load_best_model_at_end=True,\n    eval_steps=200,\n    warmup_steps=100,\n)\n\ndata_collator = DataCollatorWithPadding(tokenizer)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=valid_dataset,\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-22T21:14:44.819840Z","iopub.execute_input":"2024-10-22T21:14:44.820212Z","iopub.status.idle":"2024-10-22T21:14:46.278494Z","shell.execute_reply.started":"2024-10-22T21:14:44.820166Z","shell.execute_reply":"2024-10-22T21:14:46.277663Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-10-22T21:14:46.279575Z","iopub.execute_input":"2024-10-22T21:14:46.279889Z","iopub.status.idle":"2024-10-22T21:19:59.061395Z","shell.execute_reply.started":"2024-10-22T21:14:46.279856Z","shell.execute_reply":"2024-10-22T21:19:59.060514Z"},"trusted":true},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112489388890229, max=1.0â¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd4d15ff531544bcb7a08a673c6d8202"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241022_211534-62z3lsoa</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/its-hemangjain-delhi-technological-university/huggingface/runs/62z3lsoa' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/its-hemangjain-delhi-technological-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/its-hemangjain-delhi-technological-university/huggingface' target=\"_blank\">https://wandb.ai/its-hemangjain-delhi-technological-university/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/its-hemangjain-delhi-technological-university/huggingface/runs/62z3lsoa' target=\"_blank\">https://wandb.ai/its-hemangjain-delhi-technological-university/huggingface/runs/62z3lsoa</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1100' max='1100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1100/1100 04:19, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>200</td>\n      <td>2.819600</td>\n      <td>1.774108</td>\n      <td>0.384091</td>\n      <td>0.310445</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>1.270000</td>\n      <td>0.834167</td>\n      <td>0.650000</td>\n      <td>0.581602</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.519400</td>\n      <td>0.286404</td>\n      <td>0.877273</td>\n      <td>0.862557</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.177300</td>\n      <td>0.110856</td>\n      <td>0.979545</td>\n      <td>0.979306</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.060400</td>\n      <td>0.096488</td>\n      <td>0.975000</td>\n      <td>0.975036</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1100, training_loss=0.8839680777896535, metrics={'train_runtime': 311.2828, 'train_samples_per_second': 56.54, 'train_steps_per_second': 3.534, 'total_flos': 687501065856000.0, 'train_loss': 0.8839680777896535, 'epoch': 10.0})"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"trainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2024-10-22T21:19:59.064034Z","iopub.execute_input":"2024-10-22T21:19:59.064380Z","iopub.status.idle":"2024-10-22T21:20:00.640169Z","shell.execute_reply.started":"2024-10-22T21:19:59.064343Z","shell.execute_reply":"2024-10-22T21:20:00.639283Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [14/14 00:01]\n    </div>\n    "},"metadata":{}},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.09648821502923965,\n 'eval_accuracy': 0.975,\n 'eval_f1': 0.975036342825314,\n 'eval_runtime': 1.5648,\n 'eval_samples_per_second': 281.193,\n 'eval_steps_per_second': 8.947,\n 'epoch': 10.0}"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"model.save_pretrained('./fine_tuned_bert_model')\ntokenizer.save_pretrained('./fine_tuned_bert_model')","metadata":{"execution":{"iopub.status.busy":"2024-10-22T21:20:00.641366Z","iopub.execute_input":"2024-10-22T21:20:00.641679Z","iopub.status.idle":"2024-10-22T21:20:01.565766Z","shell.execute_reply.started":"2024-10-22T21:20:00.641645Z","shell.execute_reply":"2024-10-22T21:20:01.564813Z"},"trusted":true},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"('./fine_tuned_bert_model/tokenizer_config.json',\n './fine_tuned_bert_model/special_tokens_map.json',\n './fine_tuned_bert_model/vocab.txt',\n './fine_tuned_bert_model/added_tokens.json')"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"## Predicting Crop from features ","metadata":{}},{"cell_type":"code","source":"def predict(text):\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True).to(device)\n    model.to(device)\n    \n    outputs = model(**inputs)\n    logits = outputs.logits\n    predicted_class = torch.argmax(logits, dim=-1).item()\n    \n    return label_encoder.inverse_transform([predicted_class])[0]","metadata":{"execution":{"iopub.status.busy":"2024-10-22T21:20:01.566812Z","iopub.execute_input":"2024-10-22T21:20:01.567136Z","iopub.status.idle":"2024-10-22T21:20:01.573728Z","shell.execute_reply.started":"2024-10-22T21:20:01.567102Z","shell.execute_reply":"2024-10-22T21:20:01.572754Z"},"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"code","source":"predicted_crop = predict(\"The nitrogen content is 90, phosphorus is 42, and potassium is 43, pH is 6.50 with a temperature of 20.86896Â°C.\")\nprint(predicted_crop)","metadata":{"execution":{"iopub.status.busy":"2024-10-22T21:20:01.574823Z","iopub.execute_input":"2024-10-22T21:20:01.575101Z","iopub.status.idle":"2024-10-22T21:20:01.623834Z","shell.execute_reply.started":"2024-10-22T21:20:01.575070Z","shell.execute_reply":"2024-10-22T21:20:01.622965Z"},"trusted":true},"outputs":[{"name":"stdout","text":"jute\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"## Description of the predicted crop ","metadata":{}},{"cell_type":"code","source":"# # Load model directly\n# from transformers import AutoTokenizer, AutoModelForCausalLM\n\n# tokenizer_phi = AutoTokenizer.from_pretrained(\"microsoft/Phi-3.5-mini-instruct\", trust_remote_code=True)\n# model_phi = AutoModelForCausalLM.from_pretrained(\"microsoft/Phi-3.5-mini-instruct\", trust_remote_code=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-22T21:20:01.624945Z","iopub.execute_input":"2024-10-22T21:20:01.625228Z","iopub.status.idle":"2024-10-22T21:20:51.250179Z","shell.execute_reply.started":"2024-10-22T21:20:01.625197Z","shell.execute_reply":"2024-10-22T21:20:51.249290Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/3.98k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6012112192474172bbb37494896a6927"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db8d15ed41fe4b3492ed2744771b388d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e31676a8a1d84a2cb3683428c3ff55f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb387c42fb504d12bb8303d71b8778dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f417dfb0b704341b80fe94cfdc8cef6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/3.45k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1de186b46f804d928372bc78d4ff6045"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_phi3.py:   0%|          | 0.00/11.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1998f6fafaf342f5b09a113448fc1b53"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3.5-mini-instruct:\n- configuration_phi3.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_phi3.py:   0%|          | 0.00/73.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6b11cf6595f46f0bf10e8d1d11f9ee1"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3.5-mini-instruct:\n- modeling_phi3.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/16.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5588581cef9240b2a64627605769a1cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6453a9bda9774f09b0f9a821b9559f08"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90342fc5928047e19c9da81e455ee339"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2faa2cc58f8f4acd9ff7b3fa7a2b5cab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97b259e670984e27817dd67c9d4125d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/195 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f954ba6980e9474a8f418310e7cca2e2"}},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"!pip install bitsandbytes --no-cache-dir","metadata":{"execution":{"iopub.status.busy":"2024-10-29T09:39:50.112940Z","iopub.execute_input":"2024-10-29T09:39:50.113563Z","iopub.status.idle":"2024-10-29T09:40:01.715797Z","shell.execute_reply.started":"2024-10-29T09:39:50.113523Z","shell.execute_reply":"2024-10-29T09:40:01.714522Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (0.44.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"import bitsandbytes as bnb\nprint(bnb.__version__)  # Should match the latest version","metadata":{"execution":{"iopub.status.busy":"2024-10-29T09:40:07.636706Z","iopub.execute_input":"2024-10-29T09:40:07.637127Z","iopub.status.idle":"2024-10-29T09:40:07.642679Z","shell.execute_reply.started":"2024-10-29T09:40:07.637086Z","shell.execute_reply":"2024-10-29T09:40:07.641720Z"},"trusted":true},"outputs":[{"name":"stdout","text":"0.44.1\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"pip install -U transformers accelerate","metadata":{"execution":{"iopub.status.busy":"2024-10-29T09:40:16.857303Z","iopub.execute_input":"2024-10-29T09:40:16.858056Z","iopub.status.idle":"2024-10-29T09:40:39.771656Z","shell.execute_reply.started":"2024-10-29T09:40:16.858013Z","shell.execute_reply":"2024-10-29T09:40:39.770507Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nCollecting transformers\n  Downloading transformers-4.46.0-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.34.2)\nCollecting accelerate\n  Downloading accelerate-1.0.1-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.4.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nDownloading transformers-4.46.0-py3-none-any.whl (10.0 MB)\n\u001b[2K   \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading accelerate-1.0.1-py3-none-any.whl (330 kB)\n\u001b[2K   \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m330.9/330.9 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: accelerate, transformers\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.34.2\n    Uninstalling accelerate-0.34.2:\n      Successfully uninstalled accelerate-0.34.2\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.45.1\n    Uninstalling transformers-4.45.1:\n      Successfully uninstalled transformers-4.45.1\nSuccessfully installed accelerate-1.0.1 transformers-4.46.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig\n\nconfig = AutoConfig.from_pretrained(\"microsoft/Phi-3.5-mini-instruct\")\n\n# Load specific layers\nmodel = AutoModelForCausalLM.from_config(config)\n\n\n# # Move the model to CPU\n# model.to('cpu')\n\n# # Apply dynamic quantization\n# model = torch.quantization.quantize_dynamic(\n#     model,  # the model to quantize\n#     {torch.nn.Linear},  # quantize only the Linear layers\n#     dtype=torch.qint8  # quantize to 8-bit integers\n# )","metadata":{"execution":{"iopub.status.busy":"2024-10-29T22:27:18.682172Z","iopub.execute_input":"2024-10-29T22:27:18.682708Z","iopub.status.idle":"2024-10-29T22:28:35.990736Z","shell.execute_reply.started":"2024-10-29T22:27:18.682631Z","shell.execute_reply":"2024-10-29T22:28:35.989286Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"model.save_pretrained('./fine_tuned_phi_model')\ntokenizer.save_pretrained('./fine_tuned_phi_model')","metadata":{"execution":{"iopub.status.busy":"2024-10-29T22:02:30.327433Z","iopub.execute_input":"2024-10-29T22:02:30.328576Z","iopub.status.idle":"2024-10-29T22:03:32.478637Z","shell.execute_reply.started":"2024-10-29T22:02:30.328524Z","shell.execute_reply":"2024-10-29T22:03:32.477501Z"},"trusted":true},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"('./fine_tuned_phi_model/tokenizer_config.json',\n './fine_tuned_phi_model/special_tokens_map.json',\n './fine_tuned_phi_model/tokenizer.model',\n './fine_tuned_phi_model/added_tokens.json',\n './fine_tuned_phi_model/tokenizer.json')"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"input_text = f\"The predicted crop is {predicted_crop}. Write a paragraph about its unique characteristics, uses, and its importance in agriculture.\"\n\ninput_ids = tokenizer_phi.encode(input_text, return_tensors=\"pt\")\noutputs = model_phi.generate(input_ids=input_ids, max_length=200, num_beams=4, early_stopping=True)\n\ngenerated_text = tokenizer_phi.decode(outputs[0], skip_special_tokens=True)\nprint(generated_text)","metadata":{"execution":{"iopub.status.busy":"2024-10-22T21:20:51.251592Z","iopub.execute_input":"2024-10-22T21:20:51.251990Z","iopub.status.idle":"2024-10-22T21:24:58.849066Z","shell.execute_reply.started":"2024-10-22T21:20:51.251945Z","shell.execute_reply":"2024-10-22T21:24:58.847971Z"},"trusted":true},"outputs":[{"name":"stderr","text":"The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nThe `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n","output_type":"stream"},{"name":"stdout","text":"The predicted crop is jute. Write a paragraph about its unique characteristics, uses, and its importance in agriculture.\n\n# Answer\nJute, often referred to as the 'golden fiber,' is a long, soft, shiny bast fiber that can be spun into coarse, strong threads. It is one of the most affordable natural fibers and is second only to cotton in the amount produced and the variety of products it can be used for. Jute fibers are composed primarily of the plant materials cellulose and lignin.\n\nJute has several unique characteristics that make it highly valued in agriculture and industry. It is biodegradable, renewable, and has a low production cost, which makes it an eco-friendly alternative to synthetic fibers. The fiber is known for its high tensile strength, durability, and absorbency, which makes it suitable for a wide\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"import os\nimport shutil\n\n# Define the path to the working directory\nworking_dir = '/kaggle/working/'\n\n# Remove all files and directories in the working directory\nfor item in os.listdir(working_dir):\n    item_path = os.path.join(working_dir, item)\n    if os.path.isdir(item_path):\n        shutil.rmtree(item_path)  # Remove directory\n    else:\n        os.remove(item_path)  # Remove file\n\nprint(\"All files and directories in the working directory have been cleared.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-22T21:29:52.671338Z","iopub.execute_input":"2024-10-22T21:29:52.672315Z","iopub.status.idle":"2024-10-22T21:29:53.629033Z","shell.execute_reply.started":"2024-10-22T21:29:52.672272Z","shell.execute_reply":"2024-10-22T21:29:53.627709Z"},"trusted":true},"outputs":[{"name":"stdout","text":"All files and directories in the working directory have been cleared.\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"model_phi.save_pretrained('./fine_tuned_phi_model')\ntokenizer_phi.save_pretrained('./fine_tuned_phi_model')","metadata":{"execution":{"iopub.status.busy":"2024-10-22T21:30:00.398902Z","iopub.execute_input":"2024-10-22T21:30:00.399541Z","iopub.status.idle":"2024-10-22T21:31:01.847507Z","shell.execute_reply.started":"2024-10-22T21:30:00.399499Z","shell.execute_reply":"2024-10-22T21:31:01.846547Z"},"trusted":true},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"('./fine_tuned_phi_model/tokenizer_config.json',\n './fine_tuned_phi_model/special_tokens_map.json',\n './fine_tuned_phi_model/tokenizer.model',\n './fine_tuned_phi_model/added_tokens.json',\n './fine_tuned_phi_model/tokenizer.json')"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}